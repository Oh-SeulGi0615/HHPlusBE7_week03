## Apache Kafka
- - -
### Kafka란?
- Apache Kafka는 대량의 데이터를 실시간으로 처리하고 전송할 수 있도록 설계된 분산 스트리밍 플랫폼
- 2011년 링크드인에서 개발되어 이후 아파치 소프트웨어 재단에서 오픈소스로 관리
- 높은 확장성과 내결함성을 제공하며, 로그 데이터, 이벤트 스트리밍, 메시지 큐 시스템 등 다양한 용도로 활용

![Image](https://github.com/user-attachments/assets/e61c2428-3979-4c04-bfb7-5f4289793d07)
- kafka를 개발하기 전 링크드인의 데이터 처리 시스템
  - 통합된 전송 영역이 없어 데이터 흐름을 파악하기 어려움
  - 장애 발생 시 조치 시간 증가
  - 각 애플리케이션과 데이터 시스템 간의 별도의 파이프라인이 존재하고, 파이프라인마다 데이터 포맷과 처리 방식이 다름
  - 새로운 파이프라인 확장이 어려워 확장성과 유연성이 떨어짐

![Image](https://github.com/user-attachments/assets/a9d8d5a1-2752-4d78-ae3d-e305bb16e43a)
- kafka를 개발한 이후 링크드인의 데이터 처리 시스템
  - 모든 이벤트/데이터의 흐름을 중앙에서 관리
  - 새로운 서비스/시스템이 추가되어도 표준 포맷으로 연결하면 되므로 확장성과 신뢰성이 증가
  - 개발자는 서비스들의 비즈니스 로직에 집중 가능
- - -
### Kafka의 동작 방식과 주요 특징
- Kafka는 Pub-Sub 모델의 메세지 큐 형태로 동작
- Kafka를 이해하기 위해서는 메시지/이벤트 브로커와 메시지 큐에 대한 선제적인 이해가 필요

1. 메시지 큐 (Message Queue, MQ)
![Image](https://github.com/user-attachments/assets/0975ef68-eec8-439a-a110-b290e87f5519)
   - 메시지 큐는 메시지 지향 미들웨어 (MOM : Message Oriented Middleware)를 구현한 시스템으로 프로그램/프로세스 간의 데이터를 교환할 때 사용
   - producer : 정보를 제공
   - consumer : 정보를 제공받아 사용
   - queue : producer의 데이터를 임시 저장 및 consumer에 제공
   - 장점
     - 비동기 : queue라는 임시 저장소가 있어 나중에 처리 가능
     - 낮은 결합도 : 애플리케이션과 분리
     - 확장성 : producer or consumer 서비스를 원하는대로 확장 가능
     - 탄력성 : consumer 서비스가 다운되더라도 애플리케이션이 중단되는 것은 아니며 메시지는 MQ에 남아있음

2. 메시지 브로커 / 이벤트 브로커
- 메시지 브로커
  - publisher가 생산한 메세지를 메세지 큐에 저장하고, 저장된 데이터를 consumer가 가져갈 수 있도록 중간 다리 역할을 해주는 것이 브로커(broker)
  - 서로 다른 시스템(혹은 소프트웨어) 사이에서 데이터를 비동기 형태로 처리하기 위해 사용 (대규모 엔터프라이즈 환경의 미들웨어로서의 기능)
  - 이러한 구조를 보통 pub/sub 구조라고 하며 대표적으로는 Redis, RabbitMQ 소프트웨어가 있고, GCP의 pubsub, AWS의 SQS 같은 서비스가 있음
  - 메세지 브로커들은 consumer가 큐에서 데이터를 가져가게 되면 즉시 혹은 짧은 시간 내에 큐에서 데이터가 삭제되는 특징
- 이벤트 브로커
  - 기본적으로 메세지 브로커의 큐 기능들을 가지고 있어 메세지 브로커의 역할도 가능
  - 이벤트 브로커는 publisher가 생산한 이벤트를 이벤트 처리 후에 바로 삭제하지 않고 저장하여, 이벤트 시점이 저장되어 있어서 consumer가 특정 시점부터 이벤트를 다시 consume 할 수 있는 장점
  - 이벤트 브로커에는 Kafka, AWS의 kinesis 같은 서비스

3. Kafka의 구성 요소와 동작 원리
![Image](https://github.com/user-attachments/assets/4ab93819-c8b8-47d0-985e-89b01353600b)
- 구성 요소
  - Event : Kafka에서 producer와 consumer가 데이터를 주고받는 단위
  - Producer : Kafka에 이벤트를 게시(Post, Pub)하는 클라이언트 애플리케이션
    - 메시지를 카프카 클러스터에 전송
    - 메시지 전송 시 Batch 처리가 가능
    - Key값을 지정하여 특정 파티션으로 전송이 가능
    - 전송 acks 값을 설정하여 효율성을 높일 수 있음
      - ACKS = 0 -> 매우 빠르게 전송. 파티션 리더가 받았는 지 알 수 없음
      - ACKS = 1 -> 기본값. 파티션 리더가 받았는 지 확인
      - ACKS = ALL -> 파티션 리더 뿐 아니라 팔로워까지 메시지를 받았는지 확인
  - Consumer : Topic을 구독하고 이로부터 얻어낸 이벤트를 받아(Sub) 처리하는 클라이언트 애플리케이션
    - 메시지를 Batch처리할 수 있음
    - 한 개의 컨슈머는 여러 개의 토픽을 구독할 수 있음
    - 메시지를 소비하여도 삭제하지는 않으며 한 번 저장된 메시지를 여러번 소비도 가능
    - 한 개의 파티션은 같은 컨슈머 그룹의 여러 컨슈머에 연결할 수 없음
  - Broker : 실행된 카프카 서버
    - 서버 내부에 메시지를 저장하고 관리하는 역할
  - Topic : 이벤트가 모이는 곳
    - 각각의 메시지를 목적에 맞게 구분할 때 사용
    - 메시지를 전송하거나 소비할 때 Topic을 반드시 입력
    - Consumer는 자신이 담당하는 Topic의 메시지를 처리
    - 한 개의 토픽은 한 개 이상의 파티션으로 구성
  - Partition : Topic은 여러 Broker에 분산되어 저장되며 이렇게 분산된 Topic을 Partition이라고 함
    - Topic 생성 시 파티션의 개수를 지정할 수 있음
    - 파티션 내부에서 각 메시지는 offset으로 구분
    - 파티션이 여러개라면 kafka 클러스터가 라운드 로빈 방식으로 분배해서 분산처리
  - Zookeeper : 분산 메시지의 큐의 정보를 관리
    - 분산 애플리케이션 관리를 위한 코디네이션 시스템
    - 분산 메시지큐의 메타 정보를 중앙에서 관리
  - Offset : consumer에서 메시지를 어디까지 읽었는지 저장하는 값
    - 컨슈머 그룹의 컨슈머들은 각각의 파티션에 자신이 가져간 메시지의 위치 정보(Offset)를 기록
    - 컨슈머 장애 발생 이후 마지막으로 읽었던 위치에서부터 다시 읽어들일 수 있음
- 동작 원리
  1. publisher는 전달하고자 하는 메시지를 topic을 통해 카테고리화
  2. subscriber는 원하는 topic을 구독(=subscribe)함으로써 메시지를 읽어옴
  3. publisher와 subscriber는 오로지 topic 정보만 알 뿐, 서로에 대해 알지 못함
  4. kafka는 broker들이 하나의 클러스터로 구성되어 동작하도록 설계
  5. 클러스터 내, broker에 대한 분산처리는 ZooKeeper가 담당

4. Kafka의 주요 설계 특징
![Image](https://github.com/user-attachments/assets/73982ed4-72b5-4cf1-8868-27e156972b5e)
- 병렬로 처리하기 위해 분산 저장
- 파티션을 늘리면 메시지는 라운드 로빈 방식으로 쓰여지고, 하나의 파티션 내에서는 메시지 순서가 보장되지만 파티션이 여러개일 경우 순서가 보장되지 않음
- 한 번 늘린 파티션은 줄일 수 없음
![Image](https://github.com/user-attachments/assets/49d4ab7c-a444-40a5-bb8f-63197b3d7dc8)
- 컨슈머의 묶음을 컨슈머그룹이라고 함
- 컨슈머 그룹은 하나의 토픽에 대한 책임을 가짐